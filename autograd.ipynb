{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addace14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4908bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2521e836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e906ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "326eb181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "088732b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe87c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0 , requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e55aaada",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d81fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.sin(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8222290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3., requires_grad=True)\n",
      "tensor(9., grad_fn=<PowBackward0>)\n",
      "tensor(0.4121, grad_fn=<SinBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9396ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d5371e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.4668)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af8f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19424\\486760323.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  y.grad\n"
     ]
    }
   ],
   "source": [
    "y.grad # isn't right as y is intermediate tensor in this chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0fb75",
   "metadata": {},
   "source": [
    "### Simple Ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac96b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs \n",
    "x = torch.tensor(6.7) # input feature\n",
    "y = torch.tensor(0.0) # true label (binary)\n",
    "\n",
    "w = torch.tensor(1.0) # weight\n",
    "b = torch.tensor(0.0) # bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a04be1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary cross-entropy loss for scalar\n",
    "def binary_cross_entropy_loss(prediction, target):\n",
    "    epsilon = 1e-8 # to prevent log(0)\n",
    "    prediction = torch.clamp(prediction, epsilon , 1 - epsilon)\n",
    "    \n",
    "    return -(target * torch.log(prediction) + (1-target) * torch.log(1 - prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4770a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "z = w*x + b # weighted sum (linear part)\n",
    "y_pred = torch.sigmoid(z) # predicted probability\n",
    "\n",
    "# compute binary cross - entropy loss\n",
    "loss = binary_cross_entropy_loss(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d774910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d4774dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivatives\n",
    "\n",
    "# 1. dL/d(y_pred) \n",
    "dloss_dy_pred = (y_pred - y)/(y_pred * ( 1- y_pred))\n",
    "\n",
    "# 2. dy_pred/dz\n",
    "dy_pred_dz = y_pred * (1-y_pred)\n",
    "\n",
    "# 3. dz/dw\n",
    "dz_dw = x\n",
    "dz_db = 1\n",
    "\n",
    "dL_dw = dloss_dy_pred * dy_pred_dz * dz_dw\n",
    "dL_db = dloss_dy_pred * dy_pred_dz * dz_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a5b0b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Gradient of loss wrt weight (dw) : 6.691762447357178 \n",
      "Manual Gradient of loss wrt bias (db) : 0.998770534992218 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Manual Gradient of loss wrt weight (dw) : {dL_dw} \")\n",
    "print(f\"Manual Gradient of loss wrt bias (db) : {dL_db} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a9ccb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(6.7)\n",
    "y = torch.tensor(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab19e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0 , requires_grad= True)\n",
    "b = torch.tensor(0.0 , requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad6e15ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7000, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = w*x + b\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6951308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = torch.sigmoid(z)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d502193d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = binary_cross_entropy_loss(y_pred,y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5630140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ee045b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.6918)\n",
      "tensor(0.9988)\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7f3e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto grad on vectors\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99df8d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6667, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (x**2).mean()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6a1a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7a09457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 1.3333, 2.0000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f12a6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clearing grad\n",
    "x.grad.zero_()\n",
    "\n",
    "# in autod grad , when done backward pass multiple times then gradients tend to accumulate, which is not desiragble so we need to do clear the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to disable gradient tracking\n",
    "\n",
    "# option1 : required_grad_(False)\n",
    "# option 2 : detach()\n",
    "# option 3: torch.no_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bfa2c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad= True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74dd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.detach()\n",
    "z\n",
    "# z is same tensor as x but it doesn't have gradient tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bdabc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad= True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y = x**2\n",
    "    \n",
    "# so y won't track the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80a332ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7366de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
