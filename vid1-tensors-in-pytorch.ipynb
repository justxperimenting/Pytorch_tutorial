{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21688cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "\n",
      "  Attempting uninstall: torchvision\n",
      "\n",
      "    Found existing installation: torchvision 0.21.0\n",
      "\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "    Uninstalling torchvision-0.21.0:\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "      Successfully uninstalled torchvision-0.21.0\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "  Attempting uninstall: torchaudio\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "    Found existing installation: torchaudio 2.6.0\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "    Uninstalling torchaudio-2.6.0:\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "      Successfully uninstalled torchaudio-2.6.0\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   ---------------------------------------- 2/2 [torchaudio]\n",
      "\n",
      "Successfully installed torchaudio-2.7.0 torchvision-0.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff0f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40f34a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu not available, using cpu. \n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"gpu is available\")\n",
    "    print(f\"using gpu: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"gpu not available, using cpu. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed590367",
   "metadata": {},
   "source": [
    "## Creating a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b15555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using empty\n",
    "a = torch.empty(2,3)\n",
    "\"\"\"\n",
    "    it creates a space in mempry and it shows whatever values were in that space\n",
    "\"\"\"\n",
    "\n",
    "# type check\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c55faa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using zeros\n",
    "torch.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e43d664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using ones\n",
    "torch.ones(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff7c15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8502, 0.7708, 0.3942],\n",
       "        [0.7099, 0.1612, 0.8208]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using rand\n",
    "torch.rand(2,3) # gives random values each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e88f7459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1117, 0.8158, 0.2626],\n",
       "        [0.4839, 0.6765, 0.7539]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use of seed\n",
    "# manual seed\n",
    "torch.manual_seed(100)\n",
    "torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ddae73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1117, 0.8158, 0.2626],\n",
       "        [0.4839, 0.6765, 0.7539]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)\n",
    "torch.rand(2,3)\n",
    "# above cell gives same tensor values as seed was same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70a9b63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using tensors\n",
    "torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23c0982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using arange ->  tensor([0, 2, 4, 6, 8])\n",
      "using linspace ->  tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n",
      "         8.8889, 10.0000])\n",
      "using eye ->  tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "using full tensor([[5, 5, 5],\n",
      "        [5, 5, 5],\n",
      "        [5, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "# other methods\n",
    "\n",
    "# arange\n",
    "print(\"using arange -> \", torch.arange(0,10,2))\n",
    "\n",
    "# using linspace\n",
    "print(\"using linspace -> \", torch.linspace(0,10,10))\n",
    "\n",
    "# using eye\n",
    "print(\"using eye -> \", torch.eye(5))\n",
    "\n",
    "# using full\n",
    "print(\"using full\", torch.full((3,3), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75e8f3",
   "metadata": {},
   "source": [
    "## Tensor Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2fd9cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3], [4,5,6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fc06491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d287f137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating another tensor of same shape as above\n",
    "torch.empty_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f271dc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be9c0e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0a70d",
   "metadata": {},
   "source": [
    "## Tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2bef1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56fe4855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.0,2.0,3.0], dtype = torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2be6d62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,4], dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdf71303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using to()\n",
    "x.to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0c7ac06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2627, 0.0428, 0.2080],\n",
       "        [0.1180, 0.1217, 0.7356]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(x, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95ad97",
   "metadata": {},
   "source": [
    "## Mathematical Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b625b",
   "metadata": {},
   "source": [
    "### 1. Scaler Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43400d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9401270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9938, 0.5723, 0.0501],\n",
       "        [0.0914, 0.0318, 0.6787]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X + 2\n",
    "X - 2\n",
    "X * 3\n",
    "X / 3\n",
    "(X * 100) // 3 # integer division\n",
    "((X*100)//3)% 2 # mod\n",
    "X**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89498b87",
   "metadata": {},
   "source": [
    "### 2. Element wise operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "737434f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0169, 0.2209, 0.9535],\n",
      "        [0.7064, 0.1629, 0.8902]])\n",
      "tensor([[0.5163, 0.0359, 0.6476],\n",
      "        [0.3430, 0.3182, 0.5261]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,3)\n",
    "b = torch.rand_like(a)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9f237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0087, 0.0079, 0.6175],\n",
       "        [0.2423, 0.0518, 0.4683]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b\n",
    "a-b\n",
    "a * b\n",
    "a ** b\n",
    "a % b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b750b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.tensor([1.9,2.3,2.7,4.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4568de1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 3., 4.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round\n",
    "torch.round(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7077acfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 3., 5.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ceil\n",
    "torch.ceil(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "472a42d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 2., 4.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# floor\n",
    "torch.floor(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45e6a9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 2.3000, 2.7000, 3.0000])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clamp\n",
    "torch.clamp(d, min = 2, max = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce82279",
   "metadata": {},
   "source": [
    "### 3. Reduction Operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49f673ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 6., 7.],\n",
       "        [7., 8., 3.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.randint(size = (2,3), low = 0 , high = 10, dtype = torch.float32)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "faca577b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 25])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum\n",
    "torch.sum(e)\n",
    "#sum along columns\n",
    "torch.sum(e, dim = 0)\n",
    "# sum along the rows\n",
    "torch.sum(e , dim = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69252909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5000, 7.0000, 5.0000])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean \n",
    "torch.mean(e)\n",
    "# sum along columns\n",
    "torch.mean(e, dim = 0)\n",
    "# sum along rows\n",
    "# torch.sum(e, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50063968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max and  min \n",
    "torch.max(e)\n",
    "torch.min(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6b1726e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argmax\n",
    "torch.argmax(e) # tells position of maximum valed number \n",
    "# argmin\n",
    "torch.argmin(e) # tells position of minimum valed number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d401ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9454, 0.7116, 0.1157],\n",
      "        [0.6574, 0.3451, 0.0453]])\n",
      "tensor([[0.9798, 0.5548, 0.6868],\n",
      "        [0.4920, 0.0748, 0.9605]])\n"
     ]
    }
   ],
   "source": [
    "m = torch.rand(2,3)\n",
    "n = torch.rand(2,3)\n",
    "\n",
    "print(m)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4cf95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9251, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.add_(n) # _ means inplace operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bbac2818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9251, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8c03772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9798, 0.5548, 0.6868],\n",
       "        [0.4920, 0.0748, 0.9605]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee67d4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9251, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = m \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "535d0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we make\n",
    "m[0][0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8fa66adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then \n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ed8bb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b also changes\n",
    "b\n",
    "\n",
    "# there is not a new tensor , but a pointer pointing to tensor m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8495eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b  = m.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "95b4cf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e20838d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f10f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "m[0][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1794b0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "252bbb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.2663, 0.8025],\n",
       "        [1.1494, 0.4199, 1.0058]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5bb96",
   "metadata": {},
   "source": [
    "## Reshape Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb4935dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8680,  0.7109,  0.9353,  0.7676],\n",
       "         [-0.2889,  0.6672,  0.1637, -0.5416],\n",
       "         [-0.8724,  0.1006,  0.5509,  0.1763]],\n",
       "\n",
       "        [[ 0.0863,  0.5136,  0.1915,  0.9862],\n",
       "         [-1.5533,  0.8499,  0.4945,  0.4633],\n",
       "         [ 1.1470,  0.8598,  0.3610, -1.4282]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(2,3,4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6a19f104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8680, -0.2889, -0.8724],\n",
       "         [ 0.0863, -1.5533,  1.1470]],\n",
       "\n",
       "        [[ 0.7109,  0.6672,  0.1006],\n",
       "         [ 0.5136,  0.8499,  0.8598]],\n",
       "\n",
       "        [[ 0.9353,  0.1637,  0.5509],\n",
       "         [ 0.1915,  0.4945,  0.3610]],\n",
       "\n",
       "        [[ 0.7676, -0.5416,  0.1763],\n",
       "         [ 0.9862,  0.4633, -1.4282]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permute\n",
    "b.permute(2,0,1)\n",
    "\n",
    "# piche wala aage aa gya, aage wala beech me and beech wala piche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "061797f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 226, 226, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsqueeze\n",
    "# image size\n",
    "c = torch.rand(226,226,3)\n",
    "c.unsqueeze(0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b8e29440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze\n",
    "d = torch.rand(1,20)\n",
    "d.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9c851",
   "metadata": {},
   "source": [
    "## Numpy and Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "95b638dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "497166bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad307b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f3e8e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3fa7793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([1,2,4])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7aa139d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a5c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
